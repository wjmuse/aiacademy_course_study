{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from PIL import Image as PImage\n",
    "from os import listdir\n",
    "from pickle import dump\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL, cv2, os, json, glob, h5py, keras, csv, gc, random\n",
    "from IPython.display import SVG\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/aia-mid-term-exam-image-classification/img_classification/train'\n",
    "test_path = '../data/aia-mid-term-exam-image-classification/img_classification/test'\n",
    "model_path = '../data/aia-mid-term-exam-image-classification/img_classification/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15440062113432327275\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15770068583\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15516788639302961574\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = !ls {train_path}\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtype_dict = {}\n",
    "mtype_list = [None] * len(label_list)\n",
    "with open('../data/aia-mid-term-exam-image-classification/mid_term_mapping.csv', newline='') as csvfile:\n",
    "    _dict = csv.DictReader(csvfile)\n",
    "    for idx, row in enumerate(_dict):\n",
    "        mtype_dict[row['dirs'].strip()] = int(row['class'].strip())\n",
    "        mtype_list[int(row['class'].strip())] = row['dirs'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtype_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, Dropout, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "\n",
    "import keras.applications.xception as Xception\n",
    "import keras.applications.vgg16 as VGG16\n",
    "import keras.applications.resnet50 as resnet50\n",
    "import keras.applications.inception_v3 as InceptionV3\n",
    "import keras.applications.densenet as densenet\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "#import InceptionResNetV2, preprocess_input, decode_predictions resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = \\\n",
    "{\n",
    "    'Xception': {'target_size': (299, 299),\n",
    "                  'preprocess_input':Xception.preprocess_input,\n",
    "                  'model_obj':Xception.Xception},\n",
    "    'VGG16': {'target_size': (224, 224),\n",
    "                 'preprocess_input':VGG16.preprocess_input,\n",
    "                 'model_obj':VGG16.VGG16},\n",
    "    'ResNet50': {'target_size': (224, 224),\n",
    "                    'preprocess_input':resnet50.preprocess_input,\n",
    "                    'model_obj':resnet50.ResNet50},\n",
    "    'InceptionV3': {'target_size': (299, 299),\n",
    "                    'preprocess_input':InceptionV3.preprocess_input,\n",
    "                    'model_obj':InceptionV3.InceptionV3},\n",
    "    'DenseNet': {'target_size': (224, 224),\n",
    "              'preprocess_input':densenet.preprocess_input,\n",
    "              'model_obj':densenet.DenseNet201}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_callback(model_name):\n",
    "    top_weights_path = os.path.join(model_path, 'top_model_weights_{}.h5'.format(model_name))\n",
    "    csv_path = os.path.join(model_path, 'top_model_csv_{}.h5'.format(model_name))\n",
    "    callbacks_list = [\n",
    "        ModelCheckpoint(top_weights_path, monitor='acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='loss', patience=50, verbose=0),\n",
    "        CSVLogger(csv_path, separator=',', append=False)\n",
    "    ]\n",
    "    return (top_weights_path,csv_path,callbacks_list)\n",
    "#tensor_board = callbacks.TensorBoard()\n",
    "#set_callback('resnet_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = len(mtype_dict)\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Generator():\n",
    "    model_param = \\\n",
    "    {\n",
    "        'Xception': {'target_size': (299, 299),\n",
    "                      'preprocess_input':Xception.preprocess_input,\n",
    "                      'model_obj':Xception.Xception,\n",
    "                      'optimizer':'nadam',\n",
    "                      'nb_epoch': 40\n",
    "                    },\n",
    "        'VGG16': {'target_size': (224, 224),\n",
    "                     'preprocess_input':VGG16.preprocess_input,\n",
    "                     'model_obj':VGG16.VGG16,\n",
    "                     'rescale':1./255,\n",
    "                     'optimizer':SGD(lr=0.0001, momentum=0.9),\n",
    "                     'nb_epoch': 80\n",
    "                 },\n",
    "        'ResNet50': {'target_size': (224, 224),\n",
    "                        'preprocess_input':resnet50.preprocess_input,\n",
    "                        'model_obj':resnet50.ResNet50,\n",
    "                        'optimizer':Adam(lr=1e-5),\n",
    "                        'nb_epoch': 80\n",
    "                    },\n",
    "        'InceptionV3': {'target_size': (299, 299),\n",
    "                        'preprocess_input':InceptionV3.preprocess_input,\n",
    "                        'model_obj':InceptionV3.InceptionV3,\n",
    "                        'optimizer':'nadam',\n",
    "                        'nb_epoch': 40\n",
    "                       },\n",
    "        'DenseNet': {'target_size': (224, 224),\n",
    "                     'preprocess_input':densenet.preprocess_input,\n",
    "                     'model_obj':densenet.DenseNet201,\n",
    "                     'optimizer':SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "                     'nb_epoch': 100\n",
    "                    }\n",
    "    }\n",
    "    def __init__(self,name):\n",
    "        self.param = self.model_param[name] \n",
    "        self.modelname = name\n",
    "        self.preprocess_input = self.param['preprocess_input']\n",
    "        (self.img_width, self.img_height) = self.param['target_size']\n",
    "        self.model = self.param['model_obj'](input_shape=(self.img_width, self.img_height, 3), weights='imagenet', include_top=False)\n",
    "            \n",
    "    def get_model(self):\n",
    "        if self.modelname == 'Xception':\n",
    "            for layer in model.layers:\n",
    "                layer.trainable = False\n",
    "            x = self.model.output\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "            #x = BatchNormalization()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer=self.param['optimizer'],\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])\n",
    "        if self.modelname == 'VGG16':\n",
    "            for layer in self.model.layers:\n",
    "                layer.trainable = False\n",
    "            x = self.model.output\n",
    "            x = Flatten()(x)\n",
    "            #x = Dropout(0.2)(x)\n",
    "            #x = Dense(256, activation='relu')(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer=self.param['optimizer'],\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])\n",
    "            \n",
    "        if self.modelname == 'ResNet50':\n",
    "            for layer in self.model.layers:\n",
    "                layer.trainable = False\n",
    "            x = self.model.output\n",
    "            #x = GlobalAveragePooling2D()(x)\n",
    "            x = Flatten()(x)\n",
    "            x = Dropout(0.3)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer=self.param['optimizer'],\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])\n",
    "            \n",
    "        if self.modelname == 'InceptionV3':\n",
    "            for layer in self.model.layers:\n",
    "                layer.trainable = False\n",
    "            x = self.model.output\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "            #x = BatchNormalization()(x)\n",
    "            #x = Dropout(0.2)(x)\n",
    "            #x = Dense(256, activation='relu')(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer=self.param['optimizer'],\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])            \n",
    "                \n",
    "        if self.modelname == 'DenseNet':\n",
    "            for layer in self.model.layers:\n",
    "                layer.trainable = False\n",
    "            x = self.model.output\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "            #x = BatchNormalization()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer=self.param['optimizer'],\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])                \n",
    "                \n",
    "        return modelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train DenseNet\n",
      "Found 2957 images belonging to 5 classes.\n",
      "Found 737 images belonging to 5 classes.\n",
      "Start to fit DenseNet\n",
      "Epoch 1/100\n",
      "370/370 [==============================] - 46s 125ms/step - loss: 1.0421 - acc: 0.7420 - val_loss: 8.3257 - val_acc: 0.3460\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.74197, saving model to ../data/aia-mid-term-exam-image-classification/img_classification/model/top_model_weights_DenseNet.h5\n"
     ]
    }
   ],
   "source": [
    "for model_name in ['DenseNet']:\n",
    "    this_model = Model_Generator(model_name)\n",
    "    seed = random.randint(1, 2000)\n",
    "    print(\"Start to train %s\" % (model_name))\n",
    "    preprocess_input = this_model.param['preprocess_input']\n",
    "    (img_width, img_height) = this_model.param['target_size']\n",
    "    model = this_model.get_model()\n",
    "    nb_epoch = this_model.param['nb_epoch']\n",
    "    rescale = None\n",
    "    if 'rescale' in this_model.param:\n",
    "        rescale = this_model.param['rescale']\n",
    "\n",
    "    data_gen = image.ImageDataGenerator(validation_split=0.2,\n",
    "                                        fill_mode=\"nearest\",\n",
    "                                        rotation_range=20,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        height_shift_range=0.2,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=[0.8, 1.4],\n",
    "                                        horizontal_flip=True,\n",
    "                                        rescale=rescale)\n",
    "                                        #preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = data_gen.flow_from_directory(train_path,\n",
    "                                        target_size=(img_width, img_height),\n",
    "                                        batch_size=batch_size,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True, seed=seed, subset=\"training\")\n",
    "\n",
    "    validation_generator = data_gen.flow_from_directory(train_path,\n",
    "                                        target_size=(img_width, img_height),\n",
    "                                        batch_size=batch_size,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True, seed=seed, subset=\"validation\")\n",
    "\n",
    "    (top_weights_path,csv_path,callbacks_list) = set_callback(model_name)\n",
    "\n",
    "    print(\"Start to fit %s\" % (model_name))\n",
    "    history = model.fit_generator(train_generator,\n",
    "                        epochs=nb_epoch,\n",
    "                        validation_data=validation_generator,\n",
    "                        callbacks=callbacks_list,\n",
    "                        workers=8,\n",
    "                        use_multiprocessing=True)    \n",
    "    \n",
    "    \n",
    "    print(\"End to fit %s\" % (model_name))\n",
    "    del history\n",
    "    del this_model, model, train_generator, validation_generator, data_gen\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3694 images belonging to 5 classes.\n",
      "Found 3694 images belonging to 5 classes.\n",
      "Found 3694 images belonging to 5 classes.\n",
      "Found 3694 images belonging to 5 classes.\n",
      "Found 3694 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_param:\n",
    "    weights_path = os.path.join(model_path, 'top_model_weights_{}.h5'.format(model_name))\n",
    "    this_model = Model_Generator(model_name)\n",
    "    preprocess_input = this_model.param['preprocess_input']\n",
    "    (img_width, img_height) = this_model.param['target_size']\n",
    "    model = this_model.get_model()\n",
    "    rescale = None\n",
    "    if 'rescale' in this_model.param:\n",
    "        rescale = this_model.param['rescale']\n",
    "    \n",
    "    test_datagen = image.ImageDataGenerator(rescale=rescale, fill_mode=\"nearest\",\n",
    "                                       preprocessing_function=preprocess_input)\n",
    "\n",
    "    test_generator =  test_datagen.flow_from_directory(train_path, \n",
    "                                         target_size=(img_width, img_height), \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=None)\n",
    "    \n",
    "    \n",
    "    model.load_weights(weights_path)\n",
    "    X_l_vec = model.predict_generator(generator=test_generator, workers=8)\n",
    "    model_param[model_name]['predict'] = X_l_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l_vec = np.hstack((model_param['DenseNet']['predict'],\n",
    "                     model_param['InceptionV3']['predict'],\n",
    "                     model_param['Xception']['predict'],\n",
    "                     model_param['ResNet50']['predict'],\n",
    "                     model_param['VGG16']['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_l_vec\n",
    "Y = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_g = XGBClassifier()\n",
    "model_g.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model_g.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739, 25)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.45%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\r\n"
     ]
    }
   ],
   "source": [
    "!ls {test_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_param:\n",
    "    weights_path = os.path.join(model_path, 'top_model_weights_{}.h5'.format(model_name))\n",
    "    this_model = Model_Generator(model_name)\n",
    "    preprocess_input = this_model.param['preprocess_input']\n",
    "    (img_width, img_height) = this_model.param['target_size']\n",
    "    model = this_model.get_model()\n",
    "    rescale = None\n",
    "    if 'rescale' in this_model.param:\n",
    "        rescale = this_model.param['rescale']\n",
    "    \n",
    "    test_datagen = image.ImageDataGenerator(rescale=rescale, fill_mode=\"nearest\",\n",
    "                                       preprocessing_function=preprocess_input)\n",
    "\n",
    "    test_generator =  test_datagen.flow_from_directory(test_path, \n",
    "                                         target_size=(img_width, img_height), \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=None)\n",
    "    \n",
    "    \n",
    "    model.load_weights(weights_path)\n",
    "    X_t_vec = model.predict_generator(generator=test_generator, workers=8)\n",
    "    model_param[model_name]['predict_test'] = X_t_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_vec = np.hstack((model_param['DenseNet']['predict_test'],\n",
    "                     model_param['InceptionV3']['predict_test'],\n",
    "                     model_param['Xception']['predict_test'],\n",
    "                     model_param['ResNet50']['predict_test'],\n",
    "                     model_param['VGG16']['predict_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model_g.predict(X_t_vec)\n",
    "predictions = [round(value) for value in y_pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [_f.split('/')[1].replace('.jpg','') for _f in test_generator.filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3327 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = image.ImageDataGenerator(validation_split=0.1,\n",
    "                                        fill_mode=\"nearest\",\n",
    "                                        rotation_range=20,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        height_shift_range=0.2,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=[0.8, 1.4],\n",
    "                                        horizontal_flip=True,\n",
    "                                        rescale=rescale)\n",
    "\n",
    "train_generator = data_gen.flow_from_directory(train_path,\n",
    "                                    target_size=(img_width, img_height),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=True, seed=seed, subset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [None] * len(train_generator.class_indices)\n",
    "for _item in train_generator.class_indices:\n",
    "    class_list[train_generator.class_indices[_item]] = _item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cateidxs = [mtype_dict[class_list[_p]] for _p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_list = pd.DataFrame(\n",
    "    {'id': fnames,\n",
    "     'class': cateidxs\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_list.to_csv('stacking_5.csv',encoding='utf-8', index=False,columns=[\"id\",\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(qqm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "qqm = VGG16.VGG16(include_top=True, weights='imagenet')\n",
    "print(qqm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
