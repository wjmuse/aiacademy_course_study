{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from PIL import Image as PImage\n",
    "from os import listdir\n",
    "from pickle import dump\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL, cv2, os, json\n",
    "\n",
    "\n",
    "import keras, h5py\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set TF config \n",
    "\n",
    " - mainly used to restrict memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9693956880072670425\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5695799296\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 18126924544315920292\n",
      "physical_device_desc: \"device: 0, name: TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_0001.jpg\timage_0030.jpg\timage_0059.jpg\timage_0088.jpg\timage_0117.jpg\r\n",
      "image_0002.jpg\timage_0031.jpg\timage_0060.jpg\timage_0089.jpg\timage_0118.jpg\r\n",
      "image_0003.jpg\timage_0032.jpg\timage_0061.jpg\timage_0090.jpg\timage_0119.jpg\r\n",
      "image_0004.jpg\timage_0033.jpg\timage_0062.jpg\timage_0091.jpg\timage_0120.jpg\r\n",
      "image_0005.jpg\timage_0034.jpg\timage_0063.jpg\timage_0092.jpg\timage_0121.jpg\r\n",
      "image_0006.jpg\timage_0035.jpg\timage_0064.jpg\timage_0093.jpg\timage_0122.jpg\r\n",
      "image_0007.jpg\timage_0036.jpg\timage_0065.jpg\timage_0094.jpg\timage_0123.jpg\r\n",
      "image_0008.jpg\timage_0037.jpg\timage_0066.jpg\timage_0095.jpg\timage_0124.jpg\r\n",
      "image_0009.jpg\timage_0038.jpg\timage_0067.jpg\timage_0096.jpg\timage_0125.jpg\r\n",
      "image_0010.jpg\timage_0039.jpg\timage_0068.jpg\timage_0097.jpg\timage_0126.jpg\r\n",
      "image_0011.jpg\timage_0040.jpg\timage_0069.jpg\timage_0098.jpg\timage_0127.jpg\r\n",
      "image_0012.jpg\timage_0041.jpg\timage_0070.jpg\timage_0099.jpg\timage_0128.jpg\r\n",
      "image_0013.jpg\timage_0042.jpg\timage_0071.jpg\timage_0100.jpg\timage_0129.jpg\r\n",
      "image_0014.jpg\timage_0043.jpg\timage_0072.jpg\timage_0101.jpg\timage_0130.jpg\r\n",
      "image_0015.jpg\timage_0044.jpg\timage_0073.jpg\timage_0102.jpg\timage_0131.jpg\r\n",
      "image_0016.jpg\timage_0045.jpg\timage_0074.jpg\timage_0103.jpg\timage_0132.jpg\r\n",
      "image_0017.jpg\timage_0046.jpg\timage_0075.jpg\timage_0104.jpg\timage_0133.jpg\r\n",
      "image_0018.jpg\timage_0047.jpg\timage_0076.jpg\timage_0105.jpg\timage_0134.jpg\r\n",
      "image_0019.jpg\timage_0048.jpg\timage_0077.jpg\timage_0106.jpg\timage_0135.jpg\r\n",
      "image_0020.jpg\timage_0049.jpg\timage_0078.jpg\timage_0107.jpg\timage_0136.jpg\r\n",
      "image_0021.jpg\timage_0050.jpg\timage_0079.jpg\timage_0108.jpg\timage_0137.jpg\r\n",
      "image_0022.jpg\timage_0051.jpg\timage_0080.jpg\timage_0109.jpg\timage_0138.jpg\r\n",
      "image_0023.jpg\timage_0052.jpg\timage_0081.jpg\timage_0110.jpg\timage_0139.jpg\r\n",
      "image_0024.jpg\timage_0053.jpg\timage_0082.jpg\timage_0111.jpg\timage_0140.jpg\r\n",
      "image_0025.jpg\timage_0054.jpg\timage_0083.jpg\timage_0112.jpg\timage_0141.jpg\r\n",
      "image_0026.jpg\timage_0055.jpg\timage_0084.jpg\timage_0113.jpg\r\n",
      "image_0027.jpg\timage_0056.jpg\timage_0085.jpg\timage_0114.jpg\r\n",
      "image_0028.jpg\timage_0057.jpg\timage_0086.jpg\timage_0115.jpg\r\n",
      "image_0029.jpg\timage_0058.jpg\timage_0087.jpg\timage_0116.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../aiacademy-learning-notebook/Midterm_Image/train/CALsuburb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../../aiacademy-learning-notebook/Midterm_Image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0a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\nMjZOytGw+WRsf3avxTPzzSmVsnpX/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(os.path.join(train_dir, 'train/CALsuburb/image_0001.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../aiacademy-learning-notebook/Midterm_Image/mapping.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CALsuburb': 9,\n",
       " 'PARoffice': 7,\n",
       " 'bedroom': 12,\n",
       " 'coast': 10,\n",
       " 'forest': 4,\n",
       " 'highway': 14,\n",
       " 'industrial': 2,\n",
       " 'insidecity': 3,\n",
       " 'kitchen': 0,\n",
       " 'livingroom': 5,\n",
       " 'mountain': 8,\n",
       " 'opencountry': 6,\n",
       " 'store': 11,\n",
       " 'street': 1,\n",
       " 'tallbuilding': 13}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = dict()\n",
    "for cate,i in zip(df[0],df[1]):\n",
    "    m[cate] = i\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipulate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "                    iaa.Fliplr(0.5),               # 左右翻轉\n",
    "                    iaa.Flipud(0.5),               # 上下翻轉\n",
    "                    iaa.Affine(rotate=(-90, 90),   # 旋轉\n",
    "                    scale=(0.6, 1.4),              # 縮放\n",
    "                    mode = 'edge',                 # 影像翻轉造成區塊缺值的補值方式\n",
    "                    translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)})]) # 平移\n",
    "#img = seq.augment_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label =[]\n",
    "images_flist = []\n",
    "import os\n",
    "for cate in m.keys():\n",
    "    dc = os.path.join(train_dir, \"train/\" + cate + \"/\") \n",
    "    for fname in os.listdir(dc):\n",
    "        fpath = dc + fname\n",
    "        label.append(m[cate])\n",
    "        images_flist.append(fpath)\n",
    "\n",
    "X_imgf_train, X_imgf_test, y_train, y_test = train_test_split(images_flist, label, test_size=0.1, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = len(label)\n",
    "lc = Counter(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImg(flist, labels, is_aug=False):\n",
    "    images = []\n",
    "    r_lable = []\n",
    "    for fname,label in zip(flist,labels):\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        \n",
    "        images.append(img) \n",
    "        r_lable.append(label)     \n",
    "        \n",
    "        if is_aug==True:\n",
    "            for _ in range( int(0.3*total_images/lc[label] )  ):\n",
    "\n",
    "                resized_image = seq.augment_image(img)\n",
    "                images.append(resized_image) \n",
    "                r_lable.append(label)\n",
    "\n",
    "    return (images,r_lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train  = readImg(X_imgf_train, y_train, is_aug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show all label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 882,\n",
       "         1: 850,\n",
       "         2: 950,\n",
       "         3: 935,\n",
       "         4: 816,\n",
       "         5: 875,\n",
       "         6: 834,\n",
       "         7: 808,\n",
       "         8: 984,\n",
       "         9: 896,\n",
       "         10: 924,\n",
       "         11: 990,\n",
       "         12: 800,\n",
       "         13: 952,\n",
       "         14: 852})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[100, 100, 100],\n",
       "        [101, 101, 101],\n",
       "        [112, 112, 112],\n",
       "        ..., \n",
       "        [ 78,  78,  78],\n",
       "        [ 93,  93,  93],\n",
       "        [ 67,  67,  67]],\n",
       "\n",
       "       [[158, 158, 158],\n",
       "        [177, 177, 177],\n",
       "        [154, 154, 154],\n",
       "        ..., \n",
       "        [101, 101, 101],\n",
       "        [125, 125, 125],\n",
       "        [108, 108, 108]],\n",
       "\n",
       "       [[170, 170, 170],\n",
       "        [223, 223, 223],\n",
       "        [199, 199, 199],\n",
       "        ..., \n",
       "        [100, 100, 100],\n",
       "        [122, 122, 122],\n",
       "        [106, 106, 106]],\n",
       "\n",
       "       ..., \n",
       "       [[ 63,  63,  63],\n",
       "        [ 75,  75,  75],\n",
       "        [ 74,  74,  74],\n",
       "        ..., \n",
       "        [ 93,  93,  93],\n",
       "        [ 93,  93,  93],\n",
       "        [ 73,  73,  73]],\n",
       "\n",
       "       [[ 61,  61,  61],\n",
       "        [ 74,  74,  74],\n",
       "        [ 73,  73,  73],\n",
       "        ..., \n",
       "        [ 98,  98,  98],\n",
       "        [100, 100, 100],\n",
       "        [ 83,  83,  83]],\n",
       "\n",
       "       [[ 51,  51,  51],\n",
       "        [ 63,  63,  63],\n",
       "        [ 62,  62,  62],\n",
       "        ..., \n",
       "        [ 69,  69,  69],\n",
       "        [ 74,  74,  74],\n",
       "        [ 57,  57,  57]]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_input(X_train.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  -3.93900299,  -16.77899933,  -23.68000031],\n",
       "        [  -2.93900299,  -15.77899933,  -22.68000031],\n",
       "        [   8.06099701,   -4.77899933,  -11.68000031],\n",
       "        ..., \n",
       "        [ -25.93900299,  -38.77899933,  -45.68000031],\n",
       "        [ -10.93900299,  -23.77899933,  -30.68000031],\n",
       "        [ -36.93900299,  -49.77899933,  -56.68000031]],\n",
       "\n",
       "       [[  54.06099701,   41.22100067,   34.31999969],\n",
       "        [  73.06099701,   60.22100067,   53.31999969],\n",
       "        [  50.06099701,   37.22100067,   30.31999969],\n",
       "        ..., \n",
       "        [  -2.93900299,  -15.77899933,  -22.68000031],\n",
       "        [  21.06099701,    8.22100067,    1.31999969],\n",
       "        [   4.06099701,   -8.77899933,  -15.68000031]],\n",
       "\n",
       "       [[  66.06099701,   53.22100067,   46.31999969],\n",
       "        [ 119.06099701,  106.22100067,   99.31999969],\n",
       "        [  95.06099701,   82.22100067,   75.31999969],\n",
       "        ..., \n",
       "        [  -3.93900299,  -16.77899933,  -23.68000031],\n",
       "        [  18.06099701,    5.22100067,   -1.68000031],\n",
       "        [   2.06099701,  -10.77899933,  -17.68000031]],\n",
       "\n",
       "       ..., \n",
       "       [[ -40.93900299,  -53.77899933,  -60.68000031],\n",
       "        [ -28.93900299,  -41.77899933,  -48.68000031],\n",
       "        [ -29.93900299,  -42.77899933,  -49.68000031],\n",
       "        ..., \n",
       "        [ -10.93900299,  -23.77899933,  -30.68000031],\n",
       "        [ -10.93900299,  -23.77899933,  -30.68000031],\n",
       "        [ -30.93900299,  -43.77899933,  -50.68000031]],\n",
       "\n",
       "       [[ -42.93900299,  -55.77899933,  -62.68000031],\n",
       "        [ -29.93900299,  -42.77899933,  -49.68000031],\n",
       "        [ -30.93900299,  -43.77899933,  -50.68000031],\n",
       "        ..., \n",
       "        [  -5.93900299,  -18.77899933,  -25.68000031],\n",
       "        [  -3.93900299,  -16.77899933,  -23.68000031],\n",
       "        [ -20.93900299,  -33.77899933,  -40.68000031]],\n",
       "\n",
       "       [[ -52.93900299,  -65.77899933,  -72.68000031],\n",
       "        [ -40.93900299,  -53.77899933,  -60.68000031],\n",
       "        [ -41.93900299,  -54.77899933,  -61.68000031],\n",
       "        ..., \n",
       "        [ -34.93900299,  -47.77899933,  -54.68000031],\n",
       "        [ -29.93900299,  -42.77899933,  -49.68000031],\n",
       "        [ -46.93900299,  -59.77899933,  -66.68000031]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13348, 224, 224, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test  = readImg(X_imgf_test,y_test,is_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "X_test = preprocess_input(X_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start To Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "base_model = VGG16()\n",
    "# re-structure the model\n",
    "base_model.layers.pop()\n",
    "model = Model(inputs=base_model.inputs, outputs=[base_model.layers[-1].output])\n",
    "# summarize\n",
    "print(model.summary())\n",
    "# extract features from each photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = model.predict(X_train, verbose=0)\n",
    "X_train_new.dump(\"./X_train_new.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = model.predict(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 4096)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f571c13a240>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAAsCAYAAAB1yUN9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng8FQJhiDbjAYDGXC/wMOw9+te3tYMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(X_test_new[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import Conv2D,Dropout,BatchNormalization\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                975       \n",
      "=================================================================\n",
      "Total params: 4,265,999\n",
      "Trainable params: 4,263,951\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newInput = Input(shape=[4096])\n",
    "drop1 = Dropout(0.05)(newInput)\n",
    "d1 = Dense(1024,activation='relu',kernel_regularizer=regularizers.l1(0.0003))(drop1)\n",
    "# drop2 = Dropout(0.1)(d1)\n",
    "b1= BatchNormalization()(d1)\n",
    "d2 = Dense(64,activation='relu', kernel_regularizer=regularizers.l2(0.0003))(b1)\n",
    "output = Dense(15,activation='softmax')(d2)\n",
    "model_new = Model(inputs=[newInput], outputs=[output])\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "model_new.compile(optimizer=Adam(),\n",
    "              loss=categorical_crossentropy, metrics=['acc',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13348 samples, validate on 299 samples\n",
      "Epoch 1/20\n",
      "13348/13348 [==============================] - 3s 220us/step - loss: 3.0828 - acc: 0.7177 - val_loss: 2.9178 - val_acc: 0.7358\n",
      "Epoch 2/20\n",
      "13348/13348 [==============================] - 3s 207us/step - loss: 2.8130 - acc: 0.7255 - val_loss: 2.3448 - val_acc: 0.8227\n",
      "Epoch 3/20\n",
      "13348/13348 [==============================] - 3s 240us/step - loss: 2.6509 - acc: 0.7377 - val_loss: 2.3779 - val_acc: 0.8094\n",
      "Epoch 4/20\n",
      "13348/13348 [==============================] - 3s 225us/step - loss: 2.4155 - acc: 0.7566 - val_loss: 2.1581 - val_acc: 0.8060\n",
      "Epoch 5/20\n",
      "13348/13348 [==============================] - 3s 219us/step - loss: 2.3334 - acc: 0.7667 - val_loss: 2.1521 - val_acc: 0.7926\n",
      "Epoch 6/20\n",
      "13348/13348 [==============================] - 3s 216us/step - loss: 2.1741 - acc: 0.7768 - val_loss: 2.0673 - val_acc: 0.8261\n",
      "Epoch 7/20\n",
      "13348/13348 [==============================] - 3s 238us/step - loss: 2.0551 - acc: 0.7899 - val_loss: 2.2139 - val_acc: 0.7492\n",
      "Epoch 8/20\n",
      "13348/13348 [==============================] - 3s 213us/step - loss: 1.9604 - acc: 0.8030 - val_loss: 1.7511 - val_acc: 0.8495\n",
      "Epoch 9/20\n",
      "13348/13348 [==============================] - 3s 249us/step - loss: 1.8531 - acc: 0.8111 - val_loss: 1.7059 - val_acc: 0.8528\n",
      "Epoch 10/20\n",
      "13348/13348 [==============================] - 3s 233us/step - loss: 1.7967 - acc: 0.8231 - val_loss: 1.5882 - val_acc: 0.8863\n",
      "Epoch 11/20\n",
      "13348/13348 [==============================] - 3s 224us/step - loss: 1.6484 - acc: 0.8343 - val_loss: 1.5292 - val_acc: 0.8729\n",
      "Epoch 12/20\n",
      "13348/13348 [==============================] - 2s 186us/step - loss: 1.5713 - acc: 0.8389 - val_loss: 1.5523 - val_acc: 0.8528\n",
      "Epoch 13/20\n",
      "13348/13348 [==============================] - 2s 179us/step - loss: 1.5213 - acc: 0.8427 - val_loss: 1.5553 - val_acc: 0.8562\n",
      "Epoch 14/20\n",
      "13348/13348 [==============================] - 3s 209us/step - loss: 1.4424 - acc: 0.8468 - val_loss: 1.5307 - val_acc: 0.8763\n",
      "Epoch 15/20\n",
      "13348/13348 [==============================] - 3s 215us/step - loss: 1.4139 - acc: 0.8554 - val_loss: 1.4539 - val_acc: 0.8462\n",
      "Epoch 16/20\n",
      "13348/13348 [==============================] - 2s 185us/step - loss: 1.3456 - acc: 0.8568 - val_loss: 1.3438 - val_acc: 0.8796\n",
      "Epoch 17/20\n",
      "13348/13348 [==============================] - 2s 178us/step - loss: 1.2986 - acc: 0.8623 - val_loss: 1.3256 - val_acc: 0.8662\n",
      "Epoch 18/20\n",
      "13348/13348 [==============================] - 3s 194us/step - loss: 1.3021 - acc: 0.8645 - val_loss: 1.3120 - val_acc: 0.8863\n",
      "Epoch 19/20\n",
      "13348/13348 [==============================] - 3s 212us/step - loss: 1.2067 - acc: 0.8670 - val_loss: 1.3123 - val_acc: 0.8662\n",
      "Epoch 20/20\n",
      "13348/13348 [==============================] - 3s 205us/step - loss: 1.2329 - acc: 0.8704 - val_loss: 1.3037 - val_acc: 0.8595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f198408fba8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.fit(x = [X_train_new],\n",
    "              y = [y_train] ,\n",
    "              validation_data = [X_test_new, y_test],\n",
    "              epochs = 20,\n",
    "              shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                975       \n",
      "=================================================================\n",
      "Total params: 4,265,999\n",
      "Trainable params: 4,263,951\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.save('../model/VGG16_transfer_15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://yenlung-blog.logdown.com/posts/864703-deep-learning-keras-vgg19\n",
    "#block4_pool_features = model.predict(x)\n",
    "#plt.imshow(block4_pool_features[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
