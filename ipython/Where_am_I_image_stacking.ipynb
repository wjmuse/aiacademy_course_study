{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from PIL import Image as PImage\n",
    "from os import listdir\n",
    "from pickle import dump\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL, cv2, os, json, glob, h5py, keras, csv, gc, random\n",
    "from IPython.display import SVG\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/aia-picture-classification1/train'\n",
    "test_path = '../data/aia-picture-classification1/test'\n",
    "model_path = '../data/aia-picture-classification1/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5729061521679370824\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15787999232\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15648314789286185253\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15870492672\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16349580412776724725\n",
      "physical_device_desc: \"device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedroom',\n",
       " 'CALsuburb',\n",
       " 'coast',\n",
       " 'forest',\n",
       " 'highway',\n",
       " 'industrial',\n",
       " 'insidecity',\n",
       " 'kitchen',\n",
       " 'livingroom',\n",
       " 'mountain',\n",
       " 'opencountry',\n",
       " 'PARoffice',\n",
       " 'store',\n",
       " 'street',\n",
       " 'tallbuilding']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = !ls {train_path}\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtype_dict = {}\n",
    "mtype_list = [None] * len(label_list)\n",
    "with open('../data/aia-picture-classification1/target_to_number.txt', newline='') as csvfile:\n",
    "    _dict = csv.DictReader(csvfile)\n",
    "    for idx, row in enumerate(_dict):\n",
    "        mtype_dict[row['type'].strip()] = int(row[' index'].strip())\n",
    "        mtype_list[int(row[' index'].strip())] = row['type'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kitchen',\n",
       " 'street',\n",
       " 'industrial',\n",
       " 'insidecity',\n",
       " 'forest',\n",
       " 'livingroom',\n",
       " 'opencountry',\n",
       " 'PARoffice',\n",
       " 'mountain',\n",
       " 'CALsuburb',\n",
       " 'coast',\n",
       " 'store',\n",
       " 'bedroom',\n",
       " 'tallbuilding',\n",
       " 'highway']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtype_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, Dropout, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "\n",
    "import keras.applications.xception as Xception\n",
    "import keras.applications.vgg16 as VGG16\n",
    "import keras.applications.resnet50 as resnet50\n",
    "import keras.applications.inception_v3 as InceptionV3\n",
    "import keras.applications.densenet as densenet\n",
    "\n",
    "#import InceptionResNetV2, preprocess_input, decode_predictions resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = \\\n",
    "{\n",
    "    'Xception': {'target_size': (299, 299),\n",
    "                  'preprocess_input':Xception.preprocess_input,\n",
    "                  'model_obj':Xception.Xception},\n",
    "    'VGG16': {'target_size': (224, 224),\n",
    "                 'preprocess_input':VGG16.preprocess_input,\n",
    "                 'model_obj':VGG16.VGG16},\n",
    "    'ResNet50': {'target_size': (224, 224),\n",
    "                    'preprocess_input':resnet50.preprocess_input,\n",
    "                    'model_obj':resnet50.ResNet50},\n",
    "    'InceptionV3': {'target_size': (299, 299),\n",
    "                    'preprocess_input':InceptionV3.preprocess_input,\n",
    "                    'model_obj':InceptionV3.InceptionV3},\n",
    "    'DenseNet': {'target_size': (224, 224),\n",
    "              'preprocess_input':densenet.preprocess_input,\n",
    "              'model_obj':densenet.DenseNet201}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_callback(model_name):\n",
    "    top_weights_path = os.path.join(model_path, 'top_model_weights_{}.h5'.format(model_name))\n",
    "    csv_path = os.path.join(model_path, 'top_model_csv_{}.h5'.format(model_name))\n",
    "    callbacks_list = [\n",
    "        ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='loss', patience=15, verbose=0),\n",
    "        CSVLogger(csv_path, separator=',', append=False)\n",
    "    ]\n",
    "    return (top_weights_path,csv_path,callbacks_list)\n",
    "#tensor_board = callbacks.TensorBoard()\n",
    "#set_callback('resnet_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = len(mtype_dict)\n",
    "batch_size = 16\n",
    "nb_epoch = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Generator():\n",
    "    model_param = \\\n",
    "    {\n",
    "        'Xception': {'target_size': (299, 299),\n",
    "                      'preprocess_input':Xception.preprocess_input,\n",
    "                      'model_obj':Xception.Xception,\n",
    "                      'optimizer':'nadam'\n",
    "                    },\n",
    "        'VGG16': {'target_size': (224, 224),\n",
    "                     'preprocess_input':VGG16.preprocess_input,\n",
    "                     'model_obj':VGG16.VGG16,\n",
    "                     'rescale':1./255,\n",
    "                     'optimizer':'nadam'\n",
    "                 },\n",
    "        'ResNet50': {'target_size': (224, 224),\n",
    "                        'preprocess_input':resnet50.preprocess_input,\n",
    "                        'model_obj':resnet50.ResNet50,\n",
    "                        'optimizer':'nadam'\n",
    "                    },\n",
    "        'InceptionV3': {'target_size': (299, 299),\n",
    "                        'preprocess_input':InceptionV3.preprocess_input,\n",
    "                        'model_obj':InceptionV3.InceptionV3,\n",
    "                        'optimizer':'nadam'\n",
    "                       },\n",
    "        'DenseNet': {'target_size': (224, 224),\n",
    "                     'preprocess_input':densenet.preprocess_input,\n",
    "                     'model_obj':densenet.DenseNet201,\n",
    "                     'optimizer':'nadam'\n",
    "                    }\n",
    "    }\n",
    "    def __init__(self,name):\n",
    "        self.param = self.model_param[name] \n",
    "        self.modelname = name\n",
    "        self.preprocess_input = self.param['preprocess_input']\n",
    "        (self.img_width, self.img_height) = self.param['target_size']\n",
    "        self.model = self.param['model_obj'](input_shape=(self.img_width, self.img_height, 3), weights='imagenet', include_top=False)\n",
    "        for layer in self.model.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "    def get_model(self):\n",
    "        if self.modelname == 'Xception':\n",
    "            x = self.model.output\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer='nadam',\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])\n",
    "        if self.modelname == 'VGG16':\n",
    "            x = self.model.output\n",
    "            x = Flatten()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(256, activation='relu')(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer='nadam',\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])\n",
    "            \n",
    "        if self.modelname == 'ResNet50':\n",
    "            x = self.model.output\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer='nadam',\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])\n",
    "            \n",
    "        if self.modelname == 'InceptionV3':\n",
    "            x = self.model.output\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer='nadam',\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])            \n",
    "                \n",
    "        if self.modelname == 'DenseNet':\n",
    "            x = self.model.output\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            output = Dense(nb_classes, activation='softmax', name='softmax')(x)\n",
    "            modelf = Model(self.model.input, output)\n",
    "            modelf.compile(optimizer='nadam',\n",
    "                          loss=categorical_crossentropy, metrics=['accuracy',])                \n",
    "                \n",
    "        return modelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train Xception\n",
      "{'target_size': (299, 299), 'preprocess_input': <function preprocess_input at 0x7f0761021268>, 'model_obj': <function Xception at 0x7f07610211e0>, 'optimizer': 'nadam'}\n",
      "Found 2692 images belonging to 15 classes.\n",
      "Found 293 images belonging to 15 classes.\n",
      "Start to fit Xception\n",
      "Epoch 1/2\n",
      "169/169 [==============================] - 60s 352ms/step - loss: 1.3184 - acc: 0.5991 - val_loss: 1.2802 - val_acc: 0.6724\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67235, saving model to ../data/aia-picture-classification1/model/top_model_weights_Xception.h5\n",
      "Epoch 2/2\n",
      "169/169 [==============================] - 56s 331ms/step - loss: 0.9493 - acc: 0.7204 - val_loss: 1.3550 - val_acc: 0.6621\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.67235\n",
      "End to fit Xception\n",
      "Start to train VGG16\n",
      "{'target_size': (224, 224), 'preprocess_input': <function preprocess_input at 0x7f0761019268>, 'model_obj': <function VGG16 at 0x7f076100ae18>, 'rescale': 0.00392156862745098, 'optimizer': 'nadam'}\n",
      "0.00392156862745098\n",
      "Found 2692 images belonging to 15 classes.\n",
      "Found 293 images belonging to 15 classes.\n",
      "Start to fit VGG16\n",
      "Epoch 1/2\n",
      "169/169 [==============================] - 28s 165ms/step - loss: 3.3382 - acc: 0.3776 - val_loss: 1.2689 - val_acc: 0.5631\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.56314, saving model to ../data/aia-picture-classification1/model/top_model_weights_VGG16.h5\n",
      "Epoch 2/2\n",
      "169/169 [==============================] - 26s 152ms/step - loss: 1.2199 - acc: 0.5806 - val_loss: 0.9504 - val_acc: 0.6826\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.56314 to 0.68259, saving model to ../data/aia-picture-classification1/model/top_model_weights_VGG16.h5\n",
      "End to fit VGG16\n",
      "Start to train ResNet50\n",
      "{'target_size': (224, 224), 'preprocess_input': <function preprocess_input at 0x7f0761019268>, 'model_obj': <function ResNet50 at 0x7f0761019840>, 'optimizer': 'nadam'}\n",
      "Found 2692 images belonging to 15 classes.\n",
      "Found 293 images belonging to 15 classes.\n",
      "Start to fit ResNet50\n",
      "Epoch 1/2\n",
      "169/169 [==============================] - 14s 82ms/step - loss: 1.0892 - acc: 0.6675 - val_loss: 1.1427 - val_acc: 0.6655\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66553, saving model to ../data/aia-picture-classification1/model/top_model_weights_ResNet50.h5\n",
      "Epoch 2/2\n",
      "169/169 [==============================] - 11s 65ms/step - loss: 0.7191 - acc: 0.7881 - val_loss: 1.1179 - val_acc: 0.7065\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66553 to 0.70648, saving model to ../data/aia-picture-classification1/model/top_model_weights_ResNet50.h5\n",
      "End to fit ResNet50\n",
      "Start to train InceptionV3\n",
      "{'target_size': (299, 299), 'preprocess_input': <function preprocess_input at 0x7f0761019b70>, 'model_obj': <function InceptionV3 at 0x7f0761019ae8>, 'optimizer': 'nadam'}\n",
      "Found 2692 images belonging to 15 classes.\n",
      "Found 293 images belonging to 15 classes.\n",
      "Start to fit InceptionV3\n",
      "Epoch 1/2\n",
      "169/169 [==============================] - 61s 363ms/step - loss: 1.5360 - acc: 0.5399 - val_loss: 1.2462 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61092, saving model to ../data/aia-picture-classification1/model/top_model_weights_InceptionV3.h5\n",
      "Epoch 2/2\n",
      "169/169 [==============================] - 52s 307ms/step - loss: 1.0658 - acc: 0.6860 - val_loss: 1.4893 - val_acc: 0.6485\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.61092 to 0.64846, saving model to ../data/aia-picture-classification1/model/top_model_weights_InceptionV3.h5\n",
      "End to fit InceptionV3\n",
      "Start to train DenseNet\n",
      "{'target_size': (224, 224), 'preprocess_input': <function preprocess_input at 0x7f076102b378>, 'model_obj': <function DenseNet201 at 0x7f076102b2f0>, 'optimizer': 'nadam'}\n",
      "Found 2692 images belonging to 15 classes.\n",
      "Found 293 images belonging to 15 classes.\n",
      "Start to fit DenseNet\n",
      "Epoch 1/2\n",
      "169/169 [==============================] - 29s 170ms/step - loss: 1.0418 - acc: 0.6476 - val_loss: 0.9399 - val_acc: 0.6997\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69966, saving model to ../data/aia-picture-classification1/model/top_model_weights_DenseNet.h5\n",
      "Epoch 2/2\n",
      "169/169 [==============================] - 17s 100ms/step - loss: 0.5434 - acc: 0.8173 - val_loss: 0.9372 - val_acc: 0.7031\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69966 to 0.70307, saving model to ../data/aia-picture-classification1/model/top_model_weights_DenseNet.h5\n",
      "End to fit DenseNet\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_param:\n",
    "    this_model = Model_Generator(model_name)\n",
    "    seed = random.randint(1, 2000)\n",
    "    print(\"Start to train %s\" % (model_name))\n",
    "    preprocess_input = this_model.param['preprocess_input']\n",
    "    (img_width, img_height) = this_model.param['target_size']\n",
    "    model = this_model.get_model()\n",
    "    rescale = None\n",
    "    if 'rescale' in this_model.param:\n",
    "        rescale = this_model.param['rescale']\n",
    "\n",
    "    data_gen = image.ImageDataGenerator(validation_split=0.1,\n",
    "                                        fill_mode=\"nearest\",\n",
    "                                        rotation_range=20,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        height_shift_range=0.2,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=[0.8, 1.4],\n",
    "                                        horizontal_flip=True,\n",
    "                                        rescale=rescale,\n",
    "                                        preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = data_gen.flow_from_directory(train_path,\n",
    "                                        target_size=(img_width, img_height),\n",
    "                                        batch_size=batch_size,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True, seed=seed, subset=\"training\")\n",
    "\n",
    "    validation_generator = data_gen.flow_from_directory(train_path,\n",
    "                                        target_size=(img_width, img_height),\n",
    "                                        batch_size=batch_size,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True, seed=seed, subset=\"validation\")\n",
    "\n",
    "    (top_weights_path,csv_path,callbacks_list) = set_callback(model_name)\n",
    "\n",
    "    print(\"Start to fit %s\" % (model_name))\n",
    "    history = model.fit_generator(train_generator,\n",
    "                        epochs=2,\n",
    "                        validation_data=validation_generator,\n",
    "                        callbacks=callbacks_list,\n",
    "                        workers=8,\n",
    "                        use_multiprocessing=True)    \n",
    "    \n",
    "    \n",
    "    print(\"End to fit %s\" % (model_name))\n",
    "    del history\n",
    "    del this_model, model, train_generator, validation_generator, data_gen\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2985 images belonging to 15 classes.\n",
      "Found 2985 images belonging to 15 classes.\n",
      "Found 2985 images belonging to 15 classes.\n",
      "Found 2985 images belonging to 15 classes.\n",
      "Found 2985 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_param:\n",
    "    weights_path = os.path.join(model_path, 'top_model_weights_{}.h5'.format(model_name))\n",
    "    this_model = Model_Generator(model_name)\n",
    "    preprocess_input = this_model.param['preprocess_input']\n",
    "    (img_width, img_height) = this_model.param['target_size']\n",
    "    model = this_model.get_model()\n",
    "    rescale = None\n",
    "    if 'rescale' in this_model.param:\n",
    "        rescale = this_model.param['rescale']\n",
    "    \n",
    "    test_datagen = image.ImageDataGenerator(rescale=rescale, fill_mode=\"nearest\",\n",
    "                                       preprocessing_function=preprocess_input)\n",
    "\n",
    "    test_generator =  test_datagen.flow_from_directory(train_path, \n",
    "                                         target_size=(img_width, img_height), \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=None)\n",
    "    \n",
    "    \n",
    "    model.load_weights(weights_path)\n",
    "    X_l_vec = model.predict_generator(generator=test_generator, workers=8)\n",
    "    model_param[model_name]['predict'] = X_l_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l_vec = np.hstack((model_param['DenseNet']['predict'],\n",
    "                     model_param['InceptionV3']['predict'],\n",
    "                     model_param['Xception']['predict'],\n",
    "                     model_param['ResNet50']['predict'],\n",
    "                     model_param['VGG16']['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_l_vec\n",
    "Y = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_g = XGBClassifier()\n",
    "model_g.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model_g.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.97%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 1 classes.\n",
      "Found 1500 images belonging to 1 classes.\n",
      "Found 1500 images belonging to 1 classes.\n",
      "Found 1500 images belonging to 1 classes.\n",
      "Found 1500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_param:\n",
    "    weights_path = os.path.join(model_path, 'top_model_weights_{}.h5'.format(model_name))\n",
    "    this_model = Model_Generator(model_name)\n",
    "    preprocess_input = this_model.param['preprocess_input']\n",
    "    (img_width, img_height) = this_model.param['target_size']\n",
    "    model = this_model.get_model()\n",
    "    rescale = None\n",
    "    if 'rescale' in this_model.param:\n",
    "        rescale = this_model.param['rescale']\n",
    "    \n",
    "    test_datagen = image.ImageDataGenerator(rescale=rescale, fill_mode=\"nearest\",\n",
    "                                       preprocessing_function=preprocess_input)\n",
    "\n",
    "    test_generator =  test_datagen.flow_from_directory(test_path, \n",
    "                                         target_size=(img_width, img_height), \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=None)\n",
    "    \n",
    "    \n",
    "    model.load_weights(weights_path)\n",
    "    X_t_vec = model.predict_generator(generator=test_generator, workers=8)\n",
    "    model_param[model_name]['predict_test'] = X_t_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_vec = np.hstack((model_param['DenseNet']['predict_test'],\n",
    "                     model_param['InceptionV3']['predict_test'],\n",
    "                     model_param['Xception']['predict_test'],\n",
    "                     model_param['ResNet50']['predict_test'],\n",
    "                     model_param['VGG16']['predict_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 75)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model_g.predict(X_t_vec)\n",
    "predictions = [round(value) for value in y_pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 11, 10, 3, 7, 4, 8, 10, 7]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [_f.split('/')[1].replace('.jpg','') for _f in test_generator.filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'001d4c8d70ebf7f025fccf256324d3d5ad3560faee1cdf8c7115f5eb033bc3d2'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2692 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = image.ImageDataGenerator(validation_split=0.1,\n",
    "                                        fill_mode=\"nearest\",\n",
    "                                        rotation_range=20,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        height_shift_range=0.2,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=[0.8, 1.4],\n",
    "                                        horizontal_flip=True,\n",
    "                                        rescale=rescale,\n",
    "                                        preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = data_gen.flow_from_directory(train_path,\n",
    "                                    target_size=(img_width, img_height),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=True, seed=seed, subset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [None] * len(train_generator.class_indices)\n",
    "for _item in train_generator.class_indices:\n",
    "    class_list[train_generator.class_indices[_item]] = _item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CALsuburb': 0,\n",
       " 'PARoffice': 1,\n",
       " 'bedroom': 2,\n",
       " 'coast': 3,\n",
       " 'forest': 4,\n",
       " 'highway': 5,\n",
       " 'industrial': 6,\n",
       " 'insidecity': 7,\n",
       " 'kitchen': 8,\n",
       " 'livingroom': 9,\n",
       " 'mountain': 10,\n",
       " 'opencountry': 11,\n",
       " 'store': 12,\n",
       " 'street': 13,\n",
       " 'tallbuilding': 14}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtype_dict = {}\n",
    "mtype_list = [None] * len(label_list)\n",
    "with open('../data/aia-picture-classification1/target_to_number.txt', newline='') as csvfile:\n",
    "    _dict = csv.DictReader(csvfile)\n",
    "    for idx, row in enumerate(_dict):\n",
    "        mtype_dict[row['type'].strip()] = int(row[' index'].strip())\n",
    "        mtype_list[int(row[' index'].strip())] = row['type'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cateidxs = [mtype_dict[class_list[_p]] for _p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_list = pd.DataFrame(\n",
    "    {'id': fnames,\n",
    "     'class': cateidxs\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_list.to_csv('out_stacking_1.csv',encoding='utf-8', index=False,columns=[\"id\",\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
